\section{Introduction}\label{sec:intro}

Supervised recursive neural network models (RNNs) for sentence meaning
have been successful in an array of sophisticated language tasks,
including sentiment analysis \cite{socher2011semi,socher2013acl1},
image description \cite{sochergrounded}, and paraphrase detection
\cite{Socher-etal:2011:Paraphrase}. These results are encouraging for
the ability of these models to learn compositional semantic grammars,
but it remains an open question whether they can achieve the same
results as grammars based in logical forms
\cite{Warren:Pereira:1982,Zelle:Mooney:1996,ZetCol:2005,LiangJordan:2013}
when it comes to the core semantic concepts of quantification,
entailment, and contradiction needed to identify the labelships
between sentences like \ii{every animal walks}, \ii{every turtle
  moves}, and \ii{most reptiles don't move}. To date, experimental
investigations of these concepts using distributed representations
have been largely confined to short phrases
\cite{Mitchell:Lapata:2010,Grefenstette-etal:2011,baroni2012entailment,kalchbrenner2014convolutional}.
For robust natural language understanding, it is essential to model
these phenomena in their full generality on complex linguistic
structures.

We address this question in the context of \ii{natural language
  inference} (also known as \ii{recognizing textual entailment};
\cite{dagan2006pascal}), in which the goal is to determine the core
inferential labelship between two sentences. Much of the
theoretical work on this task (and some successful implemented models
\cite{maccartney2009extended,watanabe2012latent}) involves \ii{natural
  logics}, which are formal systems that define rules of inference
between natural language words, phrases, and sentences without the
need of intermediate representations in an artificial logical
language. Following \cite{bowman2013can}, we use the natural logic
developed by \cite{maccartney2009extended} as our formal model. This
logic defines seven core labels of synonymy, entailment,
contradiction, and mutual consistency, as summarized in
Table~\ref{b-table}, and it provides rules of semantic combination for
projecting these labels from the lexicon up to complex phrases. The
formal properties and inferential strength of this system are now
well-understood \cite{Icard:Moss:2013,Icard:Moss:2013:LILT}.

In our experiments, we use this pre-specified logical grammar to
generate controlled data sets encoding the semantic labelships
between pairs of expressions and evaluate whether each of two classes
of neural model --- plain RNNs and recursive neural tensor networks
(RNTNs, \cite{socher2013acl1}) --- can learn those labelships
correctly. In our first experiment (Section~\ref{sec:join}), we
evaluate the ability of these models to learn the core labelal
algebra of natural logic from data. Our second experiment
(Section~\ref{sec:recursion}) extends this evaluation to labels
between complex recursive structures like $(a \plor b)$ and
$\plneg(\plneg a \pland \plneg b)$, and our third experiment
(Section~\ref{sec:quantifiers}) involves labels between quantified
statements like \ii{every reptile walks} and \ii{no turtle moves}.
We find that the plain RNN achieves only mixed results in all three
experiments, whereas the stronger RNTN model generalizes well in every
case, suggesting that it has in fact learned, or at least learned to
simulate, our target logical
concepts. These experiments differentiate the increased power of RNTNs
better than previous work and provide the most convincing
demonstration to date of the ability of neural networks to model
semantic inferences in complex natural language sentences.

\begin{table}[tp]
  \centering
  \setlength{\tabcolsep}{15pt}
  \renewcommand{\arraystretch}{1.1}
  \begin{tabular}{l c l l} 
    \toprule
    Name & Symbol & Set-theoretic definition & Example \\ 
    \midrule
    entailment         & $x \natfor y$   & $x \subset y$ & \ii{turtle, reptile}  \\ 
    reverse entailment & $x \natrev y$   & $x \supset y$ & \ii{reptile, turtle}  \\ 
    equivalence        & $x \nateq y$    & $x = y$       & \ii{couch, sofa} \\ 
    alternation        & $x \natalt y$   & $x \cap y = \emptyset \wedge x \cup y \neq \mathcal{D}$ & \ii{turtle, warthog} \\ 
    negation           & $x \natneg y$   & $x \cap y = \emptyset \wedge x \cup y = \mathcal{D}$    & \ii{able, unable} \\
    cover              & $x \natcov y$   & $x \cap y \neq \emptyset \wedge x \cup y = \mathcal{D}$ & \ii{animal, non-turtle} \\ 
    independence       & $x \natind y$   & (else) & \ii{turtle, pet}\\
    \bottomrule
  \end{tabular}
  \caption{The seven natural logic labels of \cite{maccartney2009extended}. 
    $\mathcal{D}$ is the universe of possible objects of the same type as those being compared, 
    and the label $\natind$ applies whenever none of the other six do.} %, including when there 
    %is insufficient knowledge to choose a label.}
  \label{b-table}
\end{table}


% Citations to additional past work to be added.\\...\\...\\...\\...\\...


% Deep learning methods in NLP which learn vector representations for words have seen successful uses in recent years on increasingly sophisticated tasks \cite{collobert2011natural, socher2011semi, socher2013acl1, chen2013learning}. Given the still modest performance of semantically rich NLP systems in many domains---question answering and machine translation, for instance---it is worth exploring the degree to which learned vectors can serve as general purpose semantic representations. Much of the work to date analyzing vector representations for words (see \cite{baroni2013frege}) has focused on lexical semantic behaviors---like the similarity between words like \ii{Paris} and \ii{France}. Good similarity functions are valuable for many NLP tasks, but there are real use cases for which it is necessary to know how words relate to one another or to some extrinsic representation, and to model the ways in which word meanings combine to form phrase, sentence, or document meanings. This paper explores the ability of linguistic representations developed using supervised deep learning techniques to support interpretation and reasoning. 

% There are two broad family of tasks that could be used to test the ability of a model to develop general purpose meaning representations. In an interpretation task, sentences are mapped onto some denotation, such as  \ii{true} or \ii{false} for statements, or a factual answer for questions. There has been preliminary work in developing distributed models for interpretation \cite{grefenstette2013towards, rocktaschellow}, but developing a representation of world knowledge that corresponds accurately to the content expressed in language introduces considerable design challenges. I approach the problem by way of an inference task instead. Inferring the truth of one sentence from another does not require any preexisting knowledge representations, but nonetheless requires a precise representation of sentence meaning. I borrow the structure of the task from MacCartney and Manning  \cite{maccartney2009extended}. In it, the model is presented with a pair of sentences, and made to label the logical label between the sentences as equivalence, entailment, or any of five other classes, as here:

%\begin{quote}
%\begin{enumerate}\small
%\item Many smartphone users avoid high bills overseas by disabling data service.
%\item Not everyone uses their smartphones for email when traveling abroad.
%\end{enumerate} 
%$\Rightarrow$ Entailment
%\end{quote}

%In this paper, we test the ability of recursive models to on three simple tasks, each of which is meant to capture a property that is necessary in representing natural language meaning in the setting of inference. I begin with an overview of MacCartney and Manning's \cite{maccartney2009extended} framework for inference, and of the recursive neural networks that I study. by showing that these models can learn to correctly represent entailment representations between sentences. I then show that these models can capture the meanings of recursive structures accurately up to a sufficient depth. I finally close with a brief demonstration of the ability of these models to reason over short natural language sentences involving quantifiers. 

% \subsection{Natural language inference and natural logic}

% In its simplest form, \ii{natural language inference} (also known as \ii{recognizing textual entailment}, as in \cite{dagan2006pascal}) is the task of determine whether one sentence entails another. Much of the theoretical work on this task (and some successful implemented models \cite{maccartney2009natural, watanabe2012latent}) involve \ii{natural logic}, formal systems that define sound rules of inference from one sentence of natural language to another without the need for intermediate representations in some other logic. The most powerful model that we are aware of for natural logic is due to MacCartney and Manning \cite{maccartney2009extended} and Icard \cite{icard2012inclusion}, and is centered around the definition of a set of seven logical labels which can hold between sentences, shown in Table \ref{b-table}.

% This approach to natural logic can capture much of the complexity of natural language meaning within a well understood framework, and is also fairly straightforward to implement in a machine learning setting since it can be reduced to a seven-way classification problem on sentence pairs. Our goal in this paper is to learn recursive neural network models which are able to mimic key behaviors of this system.

% \begin{table}
% \begin{center}
% \begin{tabular}{|c|c|c|c|} \hline
% name & symbol & set-theoretic definition & example \\ \hline \hline
% entailment & $x \sqsubset y$ & $x \subset y$ & \ii{crow, bird}  \\ \hline
% reverse entailment & $x \sqsupset y$ & $x \supset y$ & \ii{Asian, Thai}  \\ \hline
% equivalence & $x \equiv y$ & $x = y$ & \ii{couch, sofa} \\ \hline
% alteration & $x$ $|$ $y$ & $x \cap y = \emptyset \wedge x \cup y \neq \mathcal{D}$ & \ii{cat, dog} \\ \hline
% negation & $x \natneg y$ & $x \cap y = \emptyset \wedge x \cup y = \mathcal{D}$ & \ii{able, unable} \\ \hline
% cover & $x \smallsmile y$ & $x \cap y \neq \emptyset \wedge x \cup y = \mathcal{D}$ & \ii{animal, non-ape} \\ \hline
% independence & $x$ \# $y$ & (else) & \ii{hungry, hippo}\\ \hline
% \end{tabular}
% \caption{The entailment labels in  $\mathfrak{B}$. $\mathcal{D}$ is the universe of possible objects of the same type as those being compared, and the label \# applies whenever none of the other six do, including when there is insufficient knowledge to choose a label.}
% \label{b-table}
% \end{center}
% \end{table}

% The goal of each of the three experiments that we propose is to learn classifiers that are able to classify pairs of statements from some highly constrained language into these seven classes. It should be noted that this is not a balanced classification problem. If arbitrary pairs of statements are chosen for comparison in almost any domain of natural language, the minimally informative \# label will apply between them. % TODO: How much should we say about this?


% The natural logic engine at the core of MacCartney and Manning's system requires a complex set of linguistic knowledge, much of which takes the form of what he calls projectivity signatures. These signatures are tables showing the entailment label that must hold between two strings that differ in a given way (such as the substitution of the argument of some quantifier), and are explicitly provided to the model
%for dozens of different cases of insertion, deletion and substitution of different types of lexical item. For example in judging the inference \ii{no animals bark $|$ some dogs bark} it would first used stored knowledge to compute the labels introduced by each of the two differences between the sentences. Here, the substitution of \ii{no} for \ii{some}  yields $\natneg$ and the substitution of \ii{dogs} for \ii{animals} yields $\sqsupset$. It would then use an additional store of knowledge about labels to resolve the resulting series of labels into one ($|$) that expresses the label between the two sentences being compared:
%\begin{quote}

%1. \ii{no animals bark $\natneg$ \textbf{some} animals bark}\\
%2. \ii{some animals bark $\sqsupset$ some \textbf{dogs} bark}\\
%3. \ii{no animals bark $[\natneg\bowtie\thinspace\sqsupset\thinspace = |]$ some dogs bark}

%\end{quote}

% Work to date on inference in neural network models is quite limited.
% \citet{baroni2012entailment} have achieved limited success in building a classifier to judge entailments between one- and two-word phrases (including some with quantifiers), though their vector representations were crucially based on distributional statistics and were not  learned for the task.
% In another line of research, \citet{garrette2013formal} propose a way to improve standard discrete NLI with vector representations. They propose a deterministic inference engine (similar to MacCartney's) which is augmented by a probabilistic component that evaluates individual lexical substitution steps in the derivation using vector representations, though again these representations are not learned, and no evaluations of this system have been published to date.
% \label{sec2}
