\def\year{2015}
%File: formatting-instruction.tex
\documentclass[letterpaper]{article}
\usepackage{aaai}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}

\usepackage[leqno, fleqn]{amsmath}
\usepackage{amssymb}
\usepackage{qtree}
\usepackage[numbers]{natbib}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{colortbl}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xcolor}


\frenchspacing
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}
\pdfinfo{
/Title Learning Distributed Word Representations for Natural Logic Reasoning
/Author Samuel R. Bowman, Christopher Potts, Christopher D. Manning
/Keywords distributional semantics, vector space models, natural logic, natural language processing, neural networks}
\setcounter{secnumdepth}{1}  


\newcommand{\nateq}{\equiv}
\newcommand{\natind}{\mathbin{\#}}
%\newcommand{\natneg}{\raisebox{2px}{\tiny\thinspace$\wedge$\thinspace}}
\newcommand{\natneg}{\mathbin{^{\wedge}}}
\newcommand{\natfor}{\sqsubset}
\newcommand{\natrev}{\sqsupset}
\newcommand{\natalt}{\mathbin{|}}
\newcommand{\natcov}{\mathbin{\smallsmile}}

\newcommand{\plneg}{\mathop{\textit{not}}}
\newcommand{\pland}{\mathbin{\textit{and}}}
\newcommand{\plor}{\mathbin{\textit{or}}}

% Strikeout
\newlength{\howlong}\newcommand{\strikeout}[1]{\settowidth{\howlong}{#1}#1\unitlength0.5ex%
\begin{picture}(0,0)\put(0,1){\line(-1,0){\howlong\divide\unitlength}}\end{picture}}


\newcommand{\word}[1]{\emph{#1}}
\def\ii#1{\textit{#1}}

 \begin{document}
% The file aaai.sty is the style file for AAAI Press 
% proceedings, working notes, and technical reports.
%
\title{Learning Distributed Word Representations for Natural Logic Reasoning}
\author{Samuel R. Bowman, Christopher Potts, and Christopher D. Manning\\
  Stanford University\\
  450 Serra Mall \\
  Stanford, CA 94305-2150\\
  \texttt{\{sbowman,cgpotts,manning\}@stanford.edu}} %TODO: Three affiliations?
\maketitle
\begin{abstract}
\begin{quote}
  Natural logic offers a powerful relational conception of meaning
  that is a natural counterpart to distributed semantic
  representations, which have proven valuable in a wide range of
  sophisticated language tasks. However, it remains an open question
  whether it is possible to train distributed representations to
  support the rich, diverse logical reasoning captured by natural
  logic. We address this question using two neural network-based
  models for learning embeddings: plain neural networks and neural
  tensor networks. Our experiments evaluate the models' ability to
  learn the basic algebra of natural logic relations from simulated
  data and from the WordNet noun graph.  The overall positive results
  are promising for the future of learned distributed representations in
  the applied modeling of logical semantics.
\end{quote}
\end{abstract}

Natural logic offers a powerful \emph{relational} conception of
semantics: the meanings for expressions are given, at least in part,
by their inferential connections with other expressions
\cite{Katz72,maccartney2009extended,vanBenthem08NATLOG}. For instance,
\word{turtle} is analyzed, not primarily by its extension in the
world, but rather by its lexical network: it entails \word{reptile},
excludes \word{chair}, is entailed by \word{sea
  turtle}, and so forth. With generalized notions of entailment and
contradiction, these relationships can be defined for all lexical
categories as well as complex phrases, sentences, and even texts. The
resulting theories of meaning offer valuable new analytic tools for
tasks involving database inference, relation extraction, and textual
entailment.

Natural logic aligns well with distributed (e.g., vector)
representations, which also naturally model meaning relationally.
Distributed representations have been used successfully in a wide
array of sophisticated language tasks, including part of speach tagging,
\cite{collobert2011natural}, semantic role labeling \cite{collobert2011natural},
sentiment analysis \cite{socher2011semi}, and translation \cite{sutskever2014sequence} 
among many others.
However, it remains an open question whether it is possible to train
such representations to support the rich, diverse logical reasoning
captured by natural logic; while they excel at synonymy (similarity),
the results are more mixed for entailment, contradiction, and mutual
consistency.  Using the natural logic of \cite{maccartney2009extended}
as our formal model, we address this open question using two neural
network-based models for learning embeddings: plain neural networks
and neural tensor networks (NTNs).  The natural logic is built from
the seven relations defined in Table~\ref{b-table}. Its formal
properties are now well-understood \cite{Icard:Moss:2013,Icard:Moss:2013:LILT}, so it
provides a rigorous set of goals for our neural models. To keep the
discussion manageable, we limit attention to experiments involving the
lexicon; for a more extended treatment of complex expressions
involving logical connectives and quantifiers, see
\cite{Bowman:Potts:Manning:2014}. % CITET

In our experiments, we evaluate these models' ability to learn the
basic algebra of natural logic relations from simulated data and from
the WordNet noun graph. The simulated data help us to achieve analytic
insights into what the models learn, and the WordNet data show how they
fare with a real natural language vocabulary.  We find that only the NTN is able to fully
learn the underlying algebra, but that both models excel in the 
WordNet experiment.


\begin{table*}[tp]
  \centering%\small
  \setlength{\tabcolsep}{15pt}
  \renewcommand{\arraystretch}{1.2}
  \begin{tabular}{l c l l} 
    \toprule
    Name & Symbol & Set-theoretic definition & Example \\ 
    \midrule
    entailment         & $x \natfor y$   & $x \subset y$ & \ii{turtle $\natfor$ reptile}  \\ 
    reverse entailment & $x \natrev y$   & $x \supset y$ & \ii{reptile $\natrev$ turtle}  \\ 
    equivalence        & $x \nateq y$    & $x = y$       & \ii{couch $\nateq$ sofa} \\ 
    alternation        & $x \natalt y$   & $x \cap y = \emptyset \wedge x \cup y \neq \mathcal{D}$ & \ii{turtle $\natalt$ warthog} \\ 
    negation           & $x \natneg y$   & $x \cap y = \emptyset \wedge x \cup y = \mathcal{D}$    & \ii{able $\natneg$ unable} \\
    cover              & $x \natcov y$   & $x \cap y \neq \emptyset \wedge x \cup y = \mathcal{D}$ & \ii{animal $\natcov$ non-turtle} \\ 
    independence       & $x \natind y$   & (else) & \ii{turtle $\natind$ pet}\\
    \bottomrule
  \end{tabular}
  \protect\caption{\protect\label{b-table}The seven natural logic relations of \protect\cite{maccartney2009extended}. 
    $\mathcal{D}$ is the universe of possible objects of the same type as those being compared, 
    and the relation $\natind$ applies whenever none of the other six do.} 
\end{table*}

\section{Neural network models for relation classification} \label{methods}

We build embedding-based models using the method of
\cite{Bowman:Potts:Manning:2014}, which is centered on the task of
labeling a pair of words or sentences with one of a small set of
logical relations. Unlike in a classical inference
setting, the model is not given specific premises to reason with at test time, but rather
is expected to encode all of the information that it learns about each term (word) at training
time in the term embedding vectors, and to then use only the information encoded in the relevant pair of
term vectors at test time. 
The architecture that we use is depicted in
Figure~\ref{sample-figure}. The model represents the two input terms
as single embedding vectors, which are fed into a comparison function based on one
of two types of neural network layer function to produce a
representation for the relationship between the two terms. This
representation is then fed into a softmax classifier, which outputs a
distribution over possible labels. The entire network, including the
embeddings, is trained using backpropagation with AdaGrad \cite{duchi2011adaptive}
and L2 regularization.

The simpler version of the comparison concatenates the two
input vectors before feeding them into a LReLU \cite{maasrectifier} neural network (NN)
layer.  The more powerful neural tensor network (NTN) version adds an
additional third-order tensor parameter to allow for multiplicative
interactions between the two inputs \cite{chen2013learning}. For more
details on the implementation and training of the layer functions, see
\cite{Bowman:Potts:Manning:2014}.

\begin{figure}[tp]
  \centering
    \footnotesize

	\newcommand{\labeledtreenode}[4][3]{\put(#2){\makebox(0,0){{\fcolorbox{black}{#4}{\makebox(#1,0.3){#3}}}}}}

	\newcommand{\textlabel}[4][3.5]{\put(#2){\makebox(0,0){{\makebox(#1,0.3){#3}}}}}

	\definecolor{lexcolor}{HTML}{F5F7C4}
	\definecolor{compositioncolor}{HTML}{BBEBFF}
	\definecolor{comparisoncolor}{HTML}{FFC895}
	\definecolor{softmaxcolor}{HTML}{A5FF8A}

	\setlength{\unitlength}{0.61cm}

	%\resizebox{3in}{!}{
	\begin{picture}(13.15, 5.5)
	  
	  \labeledtreenode[2.4]{6.5,5}{$P(\sqsubset) = 0.8$}{softmaxcolor}  
	  \put(6.5,3.7){\vector(0,1){1}}  
	  \labeledtreenode[5]{6.5,3.4}{turtle \emph{vs.}~animal}{comparisoncolor}


	  \textlabel{2.75,5}{Softmax classifier}{black}
	  \textlabel{2.0,3.4}{\parbox{2cm}{Comparison N(T)N layer}}{black}
	      
	  \textlabel{6.5,2.1}{Optional embedding}{black}
	  \textlabel{6.5,1.5}{transformation NN layers}{black}

	  \textlabel{6.5,0.5}{Learned term vectors}{black}
	  
	  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	  \put(1.5,0.75){\vector(0,1){0.85}}
	  \labeledtreenode{1.5,0.5}{turtle}{lexcolor}

	  \put(1.5,2.25){\vector(4,1){3.25}}
	  \labeledtreenode{1.5,1.9}{turtle}{compositioncolor}
	  
	  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	  \put(11.5,0.75){\vector(0,1){0.85}}
	  \labeledtreenode{11.5,0.5}{animal}{lexcolor}

	  \put(11.5,2.25){\vector(-4,1){3.25}}
	  \labeledtreenode{11.5,1.9}{animal}{compositioncolor}
	  
	\end{picture}
	%}
        \caption{The model structure used to compare \ii{turtle} and
          \ii{animal}.  Learned term representations are fed through
          either an NN or NTN comparison layer and then to a softmax
        classifier over the seven relations in Table~\ref{b-table}.}
  \label{sample-figure}
\end{figure}

This model used here differs from the one described in that work in
two ways. First, because the inputs are single terms, we do not use
a composition function here. Second, for our experiment on WordNet data, 
we introduce an additional $\tanh$ neural network layer between the embedding 
input and the comparison function, which facilitates initializing the 
embeddings themselves from pretrained vectors and was found to help 
performance in that setting.

%\ii{Source code and generated data will be released after the conclusion of the review period.} % TODO: Or upon request? Attach anonymized code?

\section{Reasoning about semantic relations}\label{sec:join}

In this experiment, we test our model's ability to learn and use the
natural logic inference rules schematized in
Figure~\ref{tab:jointable}. For instance, given that $a \natrev b$ and
$b \natrev c$, one can conclude that $a \natrev c$, by basic
set-theoretic reasoning (transitivity of $\natrev$). Similarly, from
$a \natfor b$ and $b \natneg c$, it follows that $a \natalt c$.  There
are 32 valid inferences that can be made on the basis of pairs of
relations of the form $a R b$ and $b R' c$. Cells in the table
containing a dot correspond to pairs of relations for which no valid
inference can be drawn in our logic.

% about the relations themselves that do not depend on the
% internal structure of the things being compared. For example, given
% that $a\sqsupset b$ and $b\sqsupset c$ one can conclude that
% $a\sqsupset c$ by the transitivity of $\sqsupset$, even without
% understanding $a$, $b$, or $c$. These seven relations support more
% than just transitivity: MacCartney and Manning's
% \cite{maccartney2009extended} join table defines 32 valid inferences
% that can be made on the basis of pairs of relations of the form $a R
% b$ and $b R' c$, including several less intuitive ones such as that if
% $a \natneg b$ and $b~|~c$ then $a \sqsupset c$.

\paragraph{Experiments}
To test our models' ability to learn these inferential patterns, we
create artificial boolean structures in which terms denote sets of entities from
a small domain (e.g., Figure~\ref{lattice-figure}), employ logical
deduction to identify the valid statements, divide those into train
and test sets, and remove from the test set those statements which
cannot be proven from the training statements
(Figure~\ref{unprovable}). 
% using the logic depicted in Figure~\ref{lattice-figure}.
%
%
% We test the model's ability to learn this behavior by creating
% artificial data sets of terms which represent sets of numbers. Since
% MacCartney and Manning's set of relations hold between sets as well as
% between sentences, we can use the underlying set structure to generate
% the all of the relations that hold between any pair of these terms, as
% in Figure \ref{lattice-figure}. We train the model defined above on a
% subset of these relations, but rather then presenting the model with a
% pair of tree-structured sentences as inputs, simply present it with
% two single terms, each of which corresponds to a single vector in the
% (randomly initialized) vocabulary matrix $V$, ensuring that the model
% has no information about the terms being compared except the relations
% between them.
%
In our experiments, we create 80 randomly generated sets drawn from a
domain of seven elements. This yields 6400 statements about pairs of
formulae, of which 3200 are chosen as a test set. 240 of the test examples 
were excluded from the primary test set for lack of evidence in the training 
data to support the choice of any one relation. 
We then trained and evaluated both the NN model and the NTN model on these data sets. 

\paragraph{Results} 
We found that the NTN model worked best with 11-dimensional vector
representations for the 80 sets and a 90-dimensional feature vector
for the classifier, though the performance of the model was not highly
dependant on either dimensionality setting. 
Averaging over five randomly generated data sets, the model was able to correctly label 98.1\% (standard error $0.67\%$) of the provably derivable test examples, and 87.7\%
($\textit{SE} = 3.59\%$) of the remaining test examples. The simpler NN worked
best with 11 and 75 dimensions, respectively, but was able to achieve
accuracies of only 84.8\% ($\textit{SE} = 0.84\%$) and 68.7\% ($\textit{SE} = 1.58\%$),
respectively. Training accuracy was 99.8\% ($\textit{SE} = 0.04\%$) for the NTN and 94.7\% ($\textit{SE} = 0.89\%$) for
the NN.

\begin{figure*}[tp]
  \centering
  \begin{subfigure}[b]{0.42\textwidth}
    \centering  
    \setlength{\arraycolsep}{8pt}
    \renewcommand{\arraystretch}{1.1}
    \newcommand{\UNK}{\cdot}  
    \resizebox{2.4in}{!}{$\begin{array}[c]{c@{ \ }|*{7}{c}|}
        % \hline
        \multicolumn{1}{c}{}
        & \nateq     & \natfor     & \natrev     & \natneg    & \natalt     & \natcov     & \multicolumn{1}{c}{\natind} \\
        \cline{2-8}
        \nateq  & \nateq &   \natfor &  \natrev &  \natneg &   \natalt &  \natcov &  \natind \\
        \natfor & \natfor &  \natfor &  \UNK &  \natalt &   \natalt &  \UNK &  \UNK \\
        \natrev & \natrev &  \UNK &  \natrev &  \natcov &   \UNK &  \natcov &  \UNK \\
        \natneg & \natneg &  \natcov &  \natalt &  \nateq &    \natrev &  \natfor &  \natind \\
        \natalt & \natalt &  \UNK &  \natalt &  \natfor &   \UNK &  \natfor &  \UNK \\
        \natcov & \natcov &  \natcov &  \UNK &  \natrev &   \natrev &  \UNK &  \UNK \\
        \natind & \natind & \UNK &  \UNK &  \natind &  \UNK &  \UNK &  \UNK \\
        \cline{2-8}
      \end{array}$}
    \caption{Inference path from premises $a\,R\,b$ (row) and $b\,S\,c$ (column) to the relation that holds between $a$ and $c$, if any.  These inferences are based on basic set-theoretic truths about the meanings of the underlying relations as described in Table~\ref{b-table}. We assess our models' ability to reproduce such inferential paths.}
    \label{tab:jointable}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \newcommand{\labelednode}[4]{\put(#1,#2){\oval(1.5,1)}\put(#1,#2){\makebox(0,0){$\begin{array}{c}#3\\\{#4\}\end{array}$}}}
    \setlength{\unitlength}{1cm}
    \resizebox{1.5in}{!}{\begin{picture}(5,5.5)
      \labelednode{2.50}{5}{}{1,2,3}
      
      \put(0.75,4){\line(3,1){1.5}}
      \put(2.5,4){\line(0,1){0.5}}
      \put(4.25,4){\line(-3,1){1.5}}
      
      \labelednode{0.75}{3.5}{a,b}{1,2}
      \labelednode{2.50}{3.5}{c}{1,3}
      \labelednode{4.25}{3.5}{d}{2,3}
      
      \put(0.75,2.5){\line(0,1){0.5}}
      \put(0.75,2.5){\line(3,1){1.5}}
      
      \put(2.5,2.5){\line(-3,1){1.5}}
      \put(2.5,2.5){\line(3,1){1.5}}
      
      \put(4.25,2.5){\line(0,1){0.5}}
      \put(4.25,2.5){\line(-3,1){1.5}}
      

      \labelednode{0.75}{2}{e,f}{1}
      \labelednode{2.50}{2}{}{2}
      \labelednode{4.25}{2}{g,h}{3}
      
      \put(2.5,1){\line(-3,1){1.5}}
      \put(2.5,1){\line(0,1){0.5}}
      \put(2.5,1){\line(3,1){1.5}}
      
      \labelednode{2.5}{0.5}{}{}
    \end{picture}}
    \caption{Simple boolean structure. The letters name the sets. Not all sets have names, and
    some sets have multiple names, so that learning $\nateq$ is non-trivial.}\label{lattice-figure}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.2\textwidth}
    \centering
    \setlength{\tabcolsep}{12pt}
    \begin{tabular}[b]{c  c}
      \toprule
      Train & Test \\
      \midrule

      $a \nateq b$              & $b \nateq b$ \\
      $a \natfor e$              & $b \natfor e$ \\
      $a \natneg g$              & \strikeout{$e \nateq f$} \\
      $d \natfor h$              & \strikeout{$g \natrev d$} \\
      $e \natalt g$            & $h \natrev d$ \\ 
      $\vdots$		& $\vdots$	\\
      \bottomrule
    \end{tabular}

    \caption{A train/test split of the atomic statements about the
      model.  Test statements not provable from the training data are
      crossed out.}\label{unprovable}
  \end{subfigure}  
  \caption{Experimental goal and set-up for reasoning about semantic relations.}
  \label{exp1}
\end{figure*} 
% Note: None of these test examples is derivable from the shown training data, 
% but we suggest that there is additional training data, so we can cross lines
% out willy-nilly without fear.

% RNTN log: tue-j-11-6x80-hip.txt
% Train PER: 0.0021875

% RNN log: tue-j-11-6x80-r-75.txt
% Train PER: 0.047188

% and create a dataset consisting of the relations between every pair of
% sets, yielding 6400 pairs. 3200 of these pairs are then chosen as a
% test dataset, and that test dataset was further split into the 2960
% examples that can be provably derived from the test data using
% MacCartney and Manning's join table (or by the symmetry of the
% relations in about half of the cases) and the 240 that
% cannot. 

% We tested a version of both the RNN model and the RNTN model on these
% data. In both cases, the models were implemented exactly as described
% in Section~\ref{methods}, but since the items being compared are
% single terms rather than full tree structures, the composition layer
% was not used, and the two models differed only in which layer function
% was used for the comparison layer. We found that the RNTN model worked
% best with 11 dimensional vector representations for the 80 sets and a
% 90 dimensional feature vector for the classifier. This model was able
% to correctly label 99.3\% of the derivable test examples, and 99.1\%
% of the remaining examples. The simpler RNN model worked best with 11
% and 75 dimensions, respectively, but was able to achieve accuracies of
% only 90.0\% and 87.\%, respectively.

These results are fairly straightforward to interpret. The NTN model
was able to accurately encode the relations between the terms in the
geometric relations between their vectors, and was able to then use
that information to recover relations that were not overtly included
in the training data. In contrast, the NN was able to achieve this
behavior only incompletely. It is possible but not likely that it
could be made to find a good solution with further optimization on
different learning algorithms, or that it would do better on a larger
universe of sets, for which there would be a larger set of training
data to learn from, but the NTN is readily able to achieve these
effects in the setting discussed here. 

It's noteworthy that both models performed well above chance on the
unprovable examples. This indicates that both were able to identify
statistical cues to the properties of the underlying boolean
structure, thereby going beyond what one could obtain from the natural
logic. Information of this kind is not sufficient to yield the
near-perfect accuracy that we saw on the provable data, but it does
highlight one of the ways in which trained inference models can turn
out to be more powerful that rigidly defined proof systems.

\newcommand{\nodagger}{\phantom{$^\dagger$}}

\begin{table*}
\centering%\resizebox{5.5in}{!}
{
  \setlength{\tabcolsep}{15pt}
  \renewcommand{\arraystretch}{1.1}
  \begin{tabular}{r r@{ }r r@{ }r r@{ }r r@{ }r r@{ }r} 
    \toprule
     Portion of & \multicolumn{4}{c}{NN} & \multicolumn{4}{c}{NTN} & \multicolumn{2}{c}{Baseline}\\
     training data  & \multicolumn{2}{c}{w/ GloVe} & \multicolumn{2}{c}{w/o GloVe} & \multicolumn{2}{c}{w/ GloVe} & \multicolumn{2}{c}{w/o GloVe} \\
    \midrule
     100\%   & 99.73 &(0.04) & 99.37$^\dagger$ &(0.14)    & 99.61 &(0.02) & \textbf{99.95}\nodagger &(0.03) & 37.05 &(--)\\
     33\%    & 95.96 &(0.20) & 95.30\nodagger &(0.12)                & 95.83 &(0.35)          & 95.45$^\dagger$ &(0.31) & 37.05 &(--)\\
     11\%    & 91.11 &(0.24) & 90.81$^\dagger$ &(0.20)    & 91.27 &(0.27)          & 90.90$^\dagger$ &(0.13) & 37.05 &(--)\\
     % 2\%    & 86.0 &(100.0) & ... &(100.0)   & 86.2 &(100.0)           & 76.4 &(87.3) & 37.9 &(--)\\ % Accidental run with slightly different train/test split.
    \bottomrule
  \end{tabular}}
 \caption{Mean test \% accuracy scores (with standard error) on the WordNet data over five-fold crossvalidation. The baseline figure is the frequency of the most frequent class, \ii{hypernym}.\label{wn-table}} 
\end{table*}

\section{Reasoning about lexical relations in WordNet}\label{sec:wordnet}

Using simulated data as above is reassuring about what the models
learn and why, but we also want to know how they perform with a real
natural language vocabulary. Unfortunately, as far as we are aware,
there are no available resources labeling such a vocabulary with the
relations from Table~\ref{b-table}. However, the relations in WordNet
\cite{fellbaum2010wordnet,WordNet95} come close and pose the same substantive
challenges within a somewhat easier classification problem.

% WordNet \cite{fellbaum2010wordnet} provides a different type of
% lattice structure which is compatible with our learning paradigm.

We extract three types of relation from WordNet. \ii{Hypernym} and
\ii{hyponym} can be represented directly in the WordNet graph
structure, and correspond closely to the $\natrev$ and $\natfor$
relations from natural logic. As in natural logic, these relations are
mirror images of one another: if \ii{dog} is a hyponym of \ii{animal}
(perhaps indirectly by way of \ii{canid}, \ii{mammal}, etc.), then
\ii{animal} is a hypernym of \ii{dog}. We also extract \ii{coordinate}
terms, which share a direct hypernym, like \ii{dalmatian}, \ii{pug},
and \ii{puppy}, which are all direct hyponyms of \ii{dog}.  Coordinate
terms tend to exclude one another, thereby providing a loose approximation 
of the natural logic exclusion relation $\natalt$. WordNet's antonym relation, however, is both too narrowly defined
and too rare to use for this purpose. WordNet defines its relations over
sets of synonyms, rather than over individual terms, so we do not
include a \ii{synonym} or \ii{equivalent} relation, but rather
consider only one member of each set of synonyms. Word pairs which do
not fall into these three relations are not included in the data set.

To limit the size of the vocabulary without otherwise simplifying the learning problem, we extract all of the
instances of these three relations for single word nouns in WordNet that are hyponyms of the node 
\texttt{organism.n.01}. In order to balance the distribution of the classes, we slightly downsample instances 
of the \ii{coordinate} relation, yielding a total of 36,772 relations among 3,217 terms. We report results below using crossvalidation, choosing a disjoint 10\% test sample for each of five runs. Unlike in the previous experiment,
it is not straightforward here to determine in advance
how much data should be required to train an accurate model, so we performed training runs with 
various fractions of the remaining data. Embeddings were fixed at 25 dimensions and were initialized 
randomly or using distributional vectors from GloVe \cite{pennington2014glove}. The feature vector 
produced by the comparison layer was fixed at 80 dimensions.

\paragraph{Results} 
The structured WordNet data contains substantially more redundancy than the random artificial data above, and we find that the NTN performs perfectly with random initialization. The plain NN performs almost as well, providing
a point of contrast with the results of Section~\ref{sec:join}. We also find that initialization with GloVe is helpful in allowing the models to maintain fair performance
with smaller amounts of training data. Some of the randomly initialized model runs failed to learn
usable representations at all and labeled all examples with the most frequent labels. We excluded these runs from the statistics, but marked settings for which this occurred with the symbol $\dagger$. For all of the remaining runs, training accuracy was consistently above 99\%.

\section{Conclusion}\label{sec:discussion}

This investigation builds upon extensive prior research on
constructing compositional word meanings in vector spaces
\cite{ClarkCoeckeSadrzadeh2011,grefenstette2013towards,Hermann-etal:2013,rocktaschellow},
extracting entailment information from distributional vector space
models \cite{baroni2012entailment,rei2014looking}, and transferring
information between logic programs and neural networks in constrained
settings \cite{hitzler2004logic,holldobler1999approximating}. Our
primary contribution is to establish a tight connection between these
approaches and formal developments within natural logic.  More
specifically, we showed that neural network models, optimized using
established techniques, can learn distributed representations that
closely approximate the behavior one would expect from a natural logic
inference algorithm.

% Ours is not the first investigation into logical behavior in vector space models: 
%  there is extensive prior work on constructing compositional word meanings in vector spaces \cite{ClarkCoeckeSadrzadeh2011,grefenstette2013towards,Hermann-etal:2013,rocktaschellow},
%  extracting entailment information from distributional vector space models \cite{baroni2012entailment,rei2014looking},
%  and transferring information between logic programs and neural networks in 
%  constrained settings \cite{holldobler1999approximating,hitzler2004logic}. However, this investigation
%   is the first that we are aware of on logical behavior in representations learned within conventionally
%    optimized neural network models.

This paper evaluated two neural models on the task of learning 
natural logic relations between distributed word representations. The
results suggest that at least the neural tensor network
has the capacity to
meet this challenge with reasonably-sized training sets, learning both 
to embed a vocabulary in a way that encodes a diverse
set of relations, and to subsequently use those embeddings to infer new
relations. In
\cite{Bowman:Potts:Manning:2014}, we extend these results to include
complex expressions involving logical connectives and quantifiers, with similar
conclusions about (tree-structured recursive versions of) these models. These findings
are promising for the future of learned distributed representations in the
applied modeling of logical semantics.

\section{Acknowledgments}

We thank Jeffrey Pennington, Richard Socher, and audiences at CSLI, Nuance, and BayLearn.


\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Baroni \bgroup et al\mbox.\egroup
  }{2012}]{baroni2012entailment}
Baroni, M.; Bernardi, R.; Do, N.-Q.; and Shan, C.-c.
\newblock 2012.
\newblock Entailment above the word level in distributional semantics.
\newblock In {\em Proc. EACL}.

\bibitem[\protect\citeauthoryear{Bowman, Potts, and
  Manning}{2014}]{Bowman:Potts:Manning:2014}
Bowman, S.; Potts, C.; and Manning, C.
\newblock 2014.
\newblock Recursive neural networks can learn logical semantics.
\newblock {arXiv} manuscript 1406.1827.

\bibitem[\protect\citeauthoryear{Chen \bgroup et al\mbox.\egroup
  }{2013}]{chen2013learning}
Chen, D.; Socher, R.; Manning, C.; and Ng, A.
\newblock 2013.
\newblock Learning new facts from knowledge bases with neural tensor networks
  and semantic word vectors.
\newblock In {\em Proc. {ICLR}}.

\bibitem[\protect\citeauthoryear{Clark, Coecke, and
  Sadrzadeh}{2011}]{ClarkCoeckeSadrzadeh2011}
Clark, S.; Coecke, B.; and Sadrzadeh, M.
\newblock 2011.
\newblock Mathematical foundations for a compositional distributed model of
  meaning.
\newblock {\em Linguistic Analysis} 36(1--4):345--384.

\bibitem[\protect\citeauthoryear{Collobert \bgroup et al\mbox.\egroup
  }{2011}]{collobert2011natural}
Collobert, R.; Weston, J.; Bottou, L.; Karlen, M.; Kavukcuoglu, K.; and Kuksa,
  P.
\newblock 2011.
\newblock Natural language processing (almost) from scratch.
\newblock {\em JLMR} 12.

\bibitem[\protect\citeauthoryear{Duchi, Hazan, and
  Singer}{2011}]{duchi2011adaptive}
Duchi, J.; Hazan, E.; and Singer, Y.
\newblock 2011.
\newblock Adaptive subgradient methods for online learning and stochastic
  optimization.
\newblock {\em JMLR}.

\bibitem[\protect\citeauthoryear{Fellbaum}{2010}]{fellbaum2010wordnet}
Fellbaum, C.
\newblock 2010.
\newblock Word{N}et.
\newblock In {\em Theory and Applications of Ontology: Computer Applications}.
  Springer.

\bibitem[\protect\citeauthoryear{Grefenstette}{2013}]{grefenstette2013towards}
Grefenstette, E.
\newblock 2013.
\newblock Towards a formal distributional semantics: Simulating logical calculi
  with tensors.
\newblock arXiv manuscript 1304.5823.

\bibitem[\protect\citeauthoryear{Hermann, Grefenstette, and
  Blunsom}{2013}]{Hermann-etal:2013}
Hermann, K.; Grefenstette, E.; and Blunsom, P.
\newblock 2013.
\newblock ``{N}ot not bad'' is not ``bad'': A distributional account of
  negation.
\newblock In {\em Proc. of the 2013 Workshop on Continuous Vector Space Models
  and their Compositionality}.

\bibitem[\protect\citeauthoryear{Hitzler, H{{\"o}}lldobler, and
  Seda}{2004}]{hitzler2004logic}
Hitzler, P.; H{{\"o}}lldobler, S.; and Seda, A.~K.
\newblock 2004.
\newblock Logic programs and connectionist networks.
\newblock {\em Journal of Applied Logic} 2(3).

\bibitem[\protect\citeauthoryear{H{\"o}lldobler, Kalinke, and
  St{\"o}rr}{1999}]{holldobler1999approximating}
H{\"o}lldobler, S.; Kalinke, Y.; and St{\"o}rr, H.-P.
\newblock 1999.
\newblock Approximating the semantics of logic programs by recurrent neural
  networks.
\newblock {\em Applied Intelligence} 11(1).

\bibitem[\protect\citeauthoryear{Icard and Moss}{2013a}]{Icard:Moss:2013}
Icard, T., and Moss, L.
\newblock 2013a.
\newblock A complete calculus of monotone and antitone higher-order functions.
\newblock In {\em Proc. Topology, Algebra, and Categories in Logic}.

\bibitem[\protect\citeauthoryear{Icard and Moss}{2013b}]{Icard:Moss:2013:LILT}
Icard, T., and Moss, L.
\newblock 2013b.
\newblock Recent progress on monotonicity.
\newblock {\em Linguistic Issues in Language Technology} 9(7).

\bibitem[\protect\citeauthoryear{Katz}{1972}]{Katz72}
Katz, J.~J.
\newblock 1972.
\newblock {\em Semantic Theory}.
\newblock New York: Harper \& Row.

\bibitem[\protect\citeauthoryear{Maas, Hannun, and Ng}{2013}]{maasrectifier}
Maas, A.; Hannun, A.; and Ng, A.
\newblock 2013.
\newblock Rectifier nonlinearities improve neural network acoustic models.
\newblock In {\em Proc. ICML}.

\bibitem[\protect\citeauthoryear{MacCartney and
  Manning}{2009}]{maccartney2009extended}
MacCartney, B., and Manning, C.
\newblock 2009.
\newblock An extended model of natural logic.
\newblock In {\em Proc. IWCS}.

\bibitem[\protect\citeauthoryear{Miller}{1995}]{WordNet95}
Miller, G.~A.
\newblock 1995.
\newblock Word{N}et: A lexical database for {E}nglish.
\newblock {\em Communications of the {ACM}} 38(11):39--41.

\bibitem[\protect\citeauthoryear{Pennington, Socher, and
  Manning}{2014}]{pennington2014glove}
Pennington, J.; Socher, R.; and Manning, C.
\newblock 2014.
\newblock Glo{V}e: {G}lobal vectors for word representation.
\newblock In {\em Proc. EMNLP}.

\bibitem[\protect\citeauthoryear{Rei and Briscoe}{2014}]{rei2014looking}
Rei, M., and Briscoe, T.
\newblock 2014.
\newblock Looking for hyponyms in vector space.
\newblock In {\em Proc. {CoNLL}}.

\bibitem[\protect\citeauthoryear{Rockt{\"a}schel \bgroup et al\mbox.\egroup
  }{2014}]{rocktaschellow}
Rockt{\"a}schel, T.; Bosnjak, M.; Singh, S.; and Riedel, S.
\newblock 2014.
\newblock Low-dimensional embeddings of logic.
\newblock In {\em Proc. the ACL 2014 Workshop on Semantic Parsing}.

\bibitem[\protect\citeauthoryear{Socher \bgroup et al\mbox.\egroup
  }{2011}]{socher2011semi}
Socher, R.; Pennington, J.; Huang, E.; Ng, A.; and Manning, C.
\newblock 2011.
\newblock Semi-supervised recursive autoencoders for predicting sentiment
  distributions.
\newblock In {\em Proc. EMNLP}.

\bibitem[\protect\citeauthoryear{Sutskever, Vinyals, and
  Le}{2014}]{sutskever2014sequence}
Sutskever, I.; Vinyals, O.; and Le, Q.
\newblock 2014.
\newblock Sequence to sequence learning with neural networks.
\newblock In {\em Proc. {NIPS}}.

\bibitem[\protect\citeauthoryear{van Benthem}{2008}]{vanBenthem08NATLOG}
van Benthem, J.
\newblock 2008.
\newblock A brief history of natural logic.
\newblock In Chakraborty, M.; L{\"o}we, B.; Nath~Mitra, M.; and Sarukki, S.,
  eds., {\em Logic, Navya-Nyaya and Applications: Homage to {B}imal {M}atilal}.

\end{thebibliography}
\bibliographystyle{aaai} 

\end{document}
