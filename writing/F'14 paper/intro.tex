\section{Introduction}\label{sec:intro}

Tree-structured recursive neural network models (TreeRNNs; \citealt{goller1996learning}) for sentence meaning
have been successful in an array of sophisticated language tasks,
including sentiment analysis \cite{socher2011semi,irsoydeep},
image description \cite{sochergrounded}, and paraphrase detection
\cite{Socher-etal:2011:Paraphrase}. These results are encouraging for
the ability of these models to learn to produce and use strong 
semantic representations for sentences. However, it remains an 
open question whether any such fully learned model can achieve the kind of
high-fidelity distributed representations proposed in recent algebraic
work on vector space modeling 
\cite{ClarkCoeckeSadrzadeh2011,grefenstette2013towards,Hermann-etal:2013,rocktaschellow},
and whether any such model can match the performance of grammars based in logical forms
in their ability to model core semantic phenomena like quantification, entailment, and contradiction \cite{Warren:Pereira:1982,Zelle:Mooney:1996,ZetCol:2005,LiangJordan:2013}.

Recent work on the algebraic approach of
\newcite{ClarkCoeckeSadrzadeh2011} has yielded rich frameworks 
for computing the meanings of fragments of natural
language compositionally from vector or tensor representations, but 
has not yet yielded effective methods for learning these representations
from data in typical machine learning settings. 
Past experimental work on reasoning with
distributed representations have been largely confined to short
phrases \cite{Mitchell:Lapata:2010,Grefenstette-etal:2011,baroni2012entailment}.
However, for robust natural language understanding, it is essential to
model these phenomena in their full generality on complex linguistic
structures. 

This paper describes four machine learning experiments
that directly evaluate the abilities of these models to learn representations that 
support specific semantic behaviors. These tasks follow the format of
 \ii{natural language inference} 
(also known as \ii{recognizing textual entailment};
\citealt{dagan2006pascal}), in which the goal is to determine the core
inferential labelship between two sentences. 
We introduce a novel NN architecture for natural language inference which
independently computes vector representations for each of two sentences using
standard TreeRNN or TreeRNTN \cite{socher2013acl1} models, and
produces a judgment for the pair using only those representations. This allows
us to gauge the abilities of these two models to represent all of the necessary semantic
information in the sentence vectors. 

Much of the
theoretical work on natural language inference (and some successful implemented models;
\citealt{maccartney2009extended,watanabe2012latent}) involves \ii{natural
  logics}, which are formal systems that define rules of inference
between natural language words, phrases, and sentences without the
need of intermediate representations in an artificial logical
language.
In our first three experiments, we test our models' ability to learn the foundations of natural
language inference by training them to reproduce the behavior of the natural logic of \newcite{maccartney2009extended} 
on artificial data. This logic
defines seven mutually-exclusive labels of synonymy, entailment, contradiction,
and mutual consistency, as summarized in Table~\ref{b-table}, and it
provides rules of semantic combination for projecting these labels
from the lexicon up to complex phrases. The formal properties of this system 
are now well-understood \cite{Icard:Moss:2013,Icard:Moss:2013:LILT}.
The first experiment using this logic 
covers reasoning with the bare logical labels (\S\ref{sec:join}), the second extends this to reasoning with statements constructed compositionally from recursive functions (\S\ref{sec:recursion}),
and the third covers the additional complexity that results from quantification (\S\ref{sec:quantifiers}).
Though the performance of the plain TreeRNN model 
 is somewhat poor in our first experiment, we find that the stronger TreeRNTN model
  generalizes well in every case, suggesting that it has learned to simulate our target logical concepts.

The experiments with simulated data provide a convincing demonstration
of the ability of neural networks to learn to build and use semantic representations for complex natural language sentences from reasonably-sized
training sets. However, we are also interested in the more practical
question of whether they can learn these representations from
naturalistic text. To address this question, we apply our models to
the SICK entailment challenge data in \S\ref{sec:sick}. The small size of this corpus puts
data-hungry NN models like ours at a disadvantage, but we are
nonetheless able to achieve competitive performance on it,
surpassing several submitted models with significant hand-engineered task-specific features and our own NN baseline.
This suggests that the representational abilities that we observe in the previous sections
are not limited to carefully circumscribed tasks. We conclude that TreeRNTN models
are adequate for typical cases of natural language inference, and that there is not yet
any clear level of inferential complexity for which other approaches work and NN models fail.

\begin{table*}[tp]
  \centering\small
  \setlength{\tabcolsep}{15pt}
  \renewcommand{\arraystretch}{1}
  \begin{tabular}{l c l l} 
    \toprule
    Name & Symbol & Set-theoretic definition & Example \\ 
    \midrule
    entailment         & $x \natfor y$   & $x \subset y$ & \ii{turtle, reptile}  \\ 
    reverse entailment & $x \natrev y$   & $x \supset y$ & \ii{reptile, turtle}  \\ 
    equivalence        & $x \nateq y$    & $x = y$       & \ii{couch, sofa} \\ 
    alternation        & $x \natalt y$   & $x \cap y = \emptyset \wedge x \cup y \neq \mathcal{D}$ & \ii{turtle, warthog} \\ 
    negation           & $x \natneg y$   & $x \cap y = \emptyset \wedge x \cup y = \mathcal{D}$    & \ii{able, unable} \\
    cover              & $x \natcov y$   & $x \cap y \neq \emptyset \wedge x \cup y = \mathcal{D}$ & \ii{animal, non-turtle} \\ 
    independence       & $x \natind y$   & (else) & \ii{turtle, pet}\\
    \bottomrule
  \end{tabular}
  \caption{\label{b-table}The seven labels of MacCartney and Manning \protect\shortcite{maccartney2009extended}'s logic are defined abstractly on pairs of sets drawing from the universe $\mathcal{D}$, but can be straightforwardly applied to any pair of natural language words, phrases, or sentences.} %-%
 
\end{table*}


% Citations to additional past work to be added.\\...\\...\\...\\...\\...


% Deep learning methods in NLP which learn vector representations for words have seen successful uses in recent years on increasingly sophisticated tasks \cite{collobert2011natural, socher2011semi, socher2013acl1, chen2013learning}. Given the still modest performance of semantically rich NLP systems in many domains---question answering and machine translation, for instance---it is worth exploring the degree to which learned vectors can serve as general purpose semantic representations. Much of the work to date analyzing vector representations for words (see \cite{baroni2013frege}) has focused on lexical semantic behaviors---like the similarity between words like \ii{Paris} and \ii{France}. Good similarity functions are valuable for many NLP tasks, but there are real use cases for which it is necessary to know how words relate to one another or to some extrinsic representation, and to model the ways in which word meanings combine to form phrase, sentence, or document meanings. This paper explores the ability of linguistic representations developed using supervised deep learning techniques to support interpretation and reasoning. 

% There are two broad family of tasks that could be used to test the ability of a model to develop general purpose meaning representations. In an interpretation task, sentences are mapped onto some denotation, such as  \ii{true} or \ii{false} for statements, or a factual answer for questions. There has been preliminary work in developing distributed models for interpretation \cite{grefenstette2013towards, rocktaschellow}, but developing a representation of world knowledge that corresponds accurately to the content expressed in language introduces considerable design challenges. I approach the problem by way of an inference task instead. Inferring the truth of one sentence from another does not require any preexisting knowledge representations, but nonetheless requires a precise representation of sentence meaning. I borrow the structure of the task from MacCartney and Manning  \cite{maccartney2009extended}. In it, the model is presented with a pair of sentences, and made to label the logical label between the sentences as equivalence, entailment, or any of five other classes, as here:

%\begin{quote}
%\begin{enumerate}\small
%\item Many smartphone users avoid high bills overseas by disabling data service.
%\item Not everyone uses their smartphones for email when traveling abroad.
%\end{enumerate} 
%$\Rightarrow$ Entailment
%\end{quote}

%In this paper, we test the ability of recursive models to on three simple tasks, each of which is meant to capture a property that is necessary in representing natural language meaning in the setting of inference. I begin with an overview of MacCartney and Manning's \cite{maccartney2009extended} framework for inference, and of the recursive neural networks that I study. by showing that these models can learn to correctly represent entailment representations between sentences. I then show that these models can capture the meanings of recursive structures accurately up to a sufficient depth. I finally close with a brief demonstration of the ability of these models to reason over short natural language sentences involving quantifiers. 

% \subsection{Natural language inference and natural logic}

% In its simplest form, \ii{natural language inference} (also known as \ii{recognizing textual entailment}, as in \cite{dagan2006pascal}) is the task of determine whether one sentence entails another. Much of the theoretical work on this task (and some successful implemented models \cite{maccartney2009natural, watanabe2012latent}) involve \ii{natural logic}, formal systems that define sound rules of inference from one sentence of natural language to another without the need for intermediate representations in some other logic. The most powerful model that we are aware of for natural logic is due to MacCartney and Manning \cite{maccartney2009extended} and Icard \cite{icard2012inclusion}, and is centered around the definition of a set of seven logical labels which can hold between sentences, shown in Table \ref{b-table}.

% This approach to natural logic can capture much of the complexity of natural language meaning within a well understood framework, and is also fairly straightforward to implement in a machine learning setting since it can be reduced to a seven-way classification problem on sentence pairs. Our goal in this paper is to learn recursive neural network models which are able to mimic key behaviors of this system.

% \begin{table}
% \begin{center}
% \begin{tabular}{|c|c|c|c|} \hline
% name & symbol & set-theoretic definition & example \\ \hline \hline
% entailment & $x \sqsubset y$ & $x \subset y$ & \ii{crow, bird}  \\ \hline
% reverse entailment & $x \sqsupset y$ & $x \supset y$ & \ii{Asian, Thai}  \\ \hline
% equivalence & $x \equiv y$ & $x = y$ & \ii{couch, sofa} \\ \hline
% alteration & $x$ $|$ $y$ & $x \cap y = \emptyset \wedge x \cup y \neq \mathcal{D}$ & \ii{cat, dog} \\ \hline
% negation & $x \natneg y$ & $x \cap y = \emptyset \wedge x \cup y = \mathcal{D}$ & \ii{able, unable} \\ \hline
% cover & $x \smallsmile y$ & $x \cap y \neq \emptyset \wedge x \cup y = \mathcal{D}$ & \ii{animal, non-ape} \\ \hline
% independence & $x$ \# $y$ & (else) & \ii{hungry, hippo}\\ \hline
% \end{tabular}
% \caption{The entailment labels in  $\mathfrak{B}$. $\mathcal{D}$ is the universe of possible objects of the same type as those being compared, and the label \# applies whenever none of the other six do, including when there is insufficient knowledge to choose a label.}
% \label{b-table}
% \end{center}
% \end{table}

% The goal of each of the three experiments that we propose is to learn classifiers that are able to classify pairs of statements from some highly constrained language into these seven classes. It should be noted that this is not a balanced classification problem. If arbitrary pairs of statements are chosen for comparison in almost any domain of natural language, the minimally informative \# label will apply between them. %  How much should we say about this?


% The natural logic engine at the core of MacCartney and Manning's system requires a complex set of linguistic knowledge, much of which takes the form of what he calls projectivity signatures. These signatures are tables showing the entailment label that must hold between two strings that differ in a given way (such as the substitution of the argument of some quantifier), and are explicitly provided to the model
%for dozens of different cases of insertion, deletion and substitution of different types of lexical item. For example in judging the inference \ii{no animals bark $|$ some dogs bark} it would first used stored knowledge to compute the labels introduced by each of the two differences between the sentences. Here, the substitution of \ii{no} for \ii{some}  yields $\natneg$ and the substitution of \ii{dogs} for \ii{animals} yields $\sqsupset$. It would then use an additional store of knowledge about labels to resolve the resulting series of labels into one ($|$) that expresses the label between the two sentences being compared:
%\begin{quote}

%1. \ii{no animals bark $\natneg$ \textbf{some} animals bark}\\
%2. \ii{some animals bark $\sqsupset$ some \textbf{dogs} bark}\\
%3. \ii{no animals bark $[\natneg\bowtie\thinspace\sqsupset\thinspace = |]$ some dogs bark}

%\end{quote}

% Work to date on inference in neural network models is quite limited.
% \citet{baroni2012entailment} have achieved limited success in building a classifier to judge entailments between one- and two-word phrases (including some with quantifiers), though their vector representations were crucially based on distributional statistics and were not  learned for the task.
% In another line of research, \citet{garrette2013formal} propose a way to improve standard discrete NLI with vector representations. They propose a deterministic inference engine (similar to MacCartney's) which is augmented by a probabilistic component that evaluates individual lexical substitution steps in the derivation using vector representations, though again these representations are not learned, and no evaluations of this system have been published to date.
% \label{sec2}
