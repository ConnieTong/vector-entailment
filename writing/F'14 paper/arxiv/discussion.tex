\section{Discussion and conclusion}\label{sec:discussion}

This paper first evaluates two recursive models on three natural language inference 
tasks over clean artificial data, covering the 
core labelal algebra of natural logic with entailment and
exclusion, recursive structure, and quantification. 
We then show that the same models can learn to
perform an entailment task on natural language. The results suggest that TreeRNTNs,
and potentially also TreeRNNs, can learn to faithfully reproduce logical inference behaviors from
reasonably-sized training sets. These positive results are
promising for the future of learned representation models in the
applied modeling of compositional semantics.

Some questions about the abilities of these models remain open. Even
the TreeRNTN falls short of perfection in the recursion experiment, with
performance falling off steadily as the size of the expressions grows. It
remains to be seen whether these deficiencies are limiting in practice,
and whether they can be overcome with
stronger models or learning techniques. In addition, interesting 
analytical questions remain about \ii{how} these models encode
the underlying logics. Neither the underlying
logical theories, nor any straightforward parameter inspection technique provides 
much insight on this point, but we hope that further experiments may reveal 
structure in the learned parameters or the representations they produce.

Our SICK experiments similarly only begin to reveal the potential of these models to learn to 
perform complex semantic inferences from corpora, and there is ample room to develop our understanding
using new and larger sources of natural language data. Nonetheless, the rapid progress the field 
has made with these models in recent years provides ample reason to be optimistic that 
learned representation models can be trained to
meet all the challenges of natural language semantics.

