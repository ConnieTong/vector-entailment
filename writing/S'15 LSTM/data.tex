\section{Recursive structure in artificial data}\label{sec:recursion}
\paragraph{Reasoning about entailment} 
The data that we use define a version of the \emph{recognizing textual entailment} task, in which the goal is to determine what kind of logical consequence relation holds between two sentences, drawing on a small fixed vocabulary of relations such as entailment, contradiction, and synonymy. This task is well suited to evaluating neural network models for sentence interpretation: models must develop comprehensive representations of the meanings of each sentence to do well at the task, but the data do not force these representations to take a specific form, allowing the model to learn whatever kind of representations it can use most effectively.

The data we use are labeled with the seven mutually exclusive logical relations of \newcite{maccartney2009extended}, which distinguish entailment in two directions ($\natfor$, $\natrev$), equivalence ($\nateq$), exhaustive and non-exhaustive contradiction ($\natneg$, $\natalt$), and two types of semantic independence ($\natind$, $\natcov$).

%\begin{table}[tp]
%  \centering\small
%  \renewcommand{\arraystretch}{1}
%  \begin{tabular}{l c l l} 
%    \toprule
%    Name & Symb. & Set-theoretic definition \\ 
%    \midrule
%strict entailment         & $\natfor$   & $x \subset y$  \\ 
%    strict rev. entailment & $\natrev$   & $x \supset y$  \\ 
%    equivalence        & $\nateq$    & $x = y$   \\ 
%    alternation        & $\natalt$   & $x \cap y = \emptyset \wedge x \cup y \neq \mathcal{D}$ \\ 
%    negation           & $\natneg$   & $x \cap y = \emptyset \wedge x \cup y = \mathcal{D}$   \\
%    cover              & $\natcov$   & $x \cap y \neq \emptyset \wedge x \cup y = \mathcal{D}$ \\ 
%    independence       & $\natind$   & (else)\\
%    \bottomrule
%  \end{tabular}
%  \caption{\label{b-table}MacCartney's seven mutually exclusive relations are defined abstractly on pairs of sets drawing from the universe $\mathcal{D}$, but can be straightforwardly applied to any pair of natural language words, phrases, or sentences.
%  } %-%
%\end{table}

\begin{table}[tp]
  \centering\small
%  \begin{subtable}[t]{0.45\textwidth}
%    \centering
%    \begin{tabular}[t]{l l}
%      \toprule
%      Formula     & Interpretation \\
%      \midrule
%      $p_1$, $p_2$, $p_3$, $p_4$, $p_5$, $p_6$ & $\sem{x} \in \{\True, \False\}$ \\
%      $\plneg \varphi$ & $\True$ iff $\sem{\varphi} = \False$ \\
%      $(\varphi \pland \psi)$ & $\True$ iff $\False \notin \{\sem{\varphi}, \sem{\psi}\}$ \\
%      $(\varphi \plor \psi)$  & $\True$ iff $\True \in \{\sem{\varphi}, \sem{\psi}\}$ \\
%      \bottomrule
%    \end{tabular}    
%    \caption{Well-formed formulae. $\varphi$ and $\psi$
%      range over all well-formed formulae, and $\sem{\cdot}$ is
%      the interpretation function mapping formulae into $\{\True,
%      \False\}$.}\label{tab:pl}
%  \end{subtable}
    \begin{tabular}[t]{r c l}
      \toprule
      $\plneg p_3$        & $\natneg$ & $p_3$ \\
%      $\plneg \plneg p_6$ & $\nateq$  & $p_6$ \\
      $p_3$               & $\natfor$ & $p_3 \plor p_2$ \\
%      $p_1 \plor (p_2 \plor p_4)$               & $\natrev$ & $p_2 \pland  \plneg p_4$ \\
      $(\plneg p_2) \pland p_6  $ & $\natalt$ & $     \plneg ( p_6 \plor ( p_5 \plor p_3 ) ) $\\
      %$(a \natfor b)$   & $\nateq$  & $(b \natrev a)$ \\	
 $    p_4 \plor ( \plneg ( ( p_1   $ & $ \natfor $ & $  \plneg ( ( ( ( \plneg p_6 ) \plor ( \plneg p_4 ) )   $\\      
$ \plor p_6 )  \plor p_4 ) )$ &&$ \pland ( \plneg p_5 ) )\pland ( p_6 \pland p_6 ) ) $\\
% $(p_3 \pland \plneg p_1 ) \plor \plneg p_3$    & $\natrev$& $\plneg\, (p_3 \plor p_2)$ \\
      %<	( not ( c ( or b ) ) )	( ( c ( and ( not a ) ) ) ( or ( not c ) ) )
      \bottomrule
    \end{tabular}
    \caption{Examples of short to moderate length pairs from the artificial data introduced in \protect\citealt{Bowman:Potts:Manning:2014}. We only show the parentheses that are needed to disambiguate the sentences rather than the full binary bracketings.}\label{tab:plexs}
\end{table}


\paragraph{The artificial language} The language described in Bowman et al.~(\S4) is designed to highlight the use of recursive structure with minimal additional complexity. Its vocabulary consists only of six unanalyzed word types ($p_1, p_2, p_3, p_4, p_5, p_6$), \word{and}, \word{or}, and \word{not}. Sentences of the language can be straightforwardly interpreted as statements of propositional logic (where the six unanalyzed words are variables), and labeled sentence pairs can be interpreted as theorems of that logic. Some example pairs are provided in Table~\ref{tab:plexs}.

Crucially, the language is defined such that any sentence can be embedded under negation or conjunction to create a new sentence, allowing for arbitrary-depth recursion, and the scope of negation and conjunction are determined only by bracketing with parentheses (rather than bare word order). The compositional structure of each sentence can thus be an arbitrary tree, and interpreting a sentence correctly requires using that structure.

The data come with parentheses representing a complete binary bracketing. Our models use this information in two ways. For the tree models, the parentheses are not word tokens, but rather used in the expected way to build the tree. For the sequence model, the parentheses are words with associated learned embeddings. This provides the models with equivalent data, so their ability to handle unseen structures can be fairly compared.

\paragraph{The corpus}
The sentence pairs in the corpus are divided into thirteen bins according to the number of logical connectives (\word{and, or, not}) in the longer of the two sentences in the pair. We test the model on each bin separately (58k total examples, using an 80/20\% train/test split) in order to evaluate how its performance depends on the complexity of the sentences. In three experiments, we train our models on the training portions of bins 0--3 (62k examples), 0--4 (90k), and 0--6 (160k), and test on every bin but the trivial bin 0. Capping the size of the training sentences allows us to evaluate how the models interpret the sentences: if their performance falls off abruptly above the cutoff, it is reasonable to assume that the models are depending heavily on specific sentence structures, and cannot generalize to new structures. If their performance decays gradually\footnote{Since sentences are fixed-dimensional vectors of fixed-precision floating point numbers, all models will make errors on sentences above some length, and L2 regularization (which helps overall performance) exacerbates this by discouraging the model from using the kind of numerically precise, nonlinearity-saturating functions that generalize best.} with no such abrupt change, then it must have learned a more generally valid interpretation function for the language which respects its recursive structure.



